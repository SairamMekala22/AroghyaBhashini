# ğŸ©º Aroghyabhashini  
> Empowering Communication Through Technology

---

## ğŸ§  Project Overview  

**Aroghyabhashini** is an innovative assistive communication system designed to give voice to the voiceless â€” specifically for individuals who cannot speak or have severe speech impairments.  

The system uses **AI**, **translation**, and **speech synthesis technologies** to interpret user input (typed, selected, or sensor-based) and convert it into **natural-sounding speech**.  

The name â€œAroghyabhashiniâ€ symbolizes *â€œHealthy Speechâ€* â€” a voice for those who cannot speak.  

### ğŸ¯ Our Goal
To develop a scalable, accessible, and AI-powered communication platform that helps mute or speech-impaired people express their thoughts clearly and confidently.

---

## ğŸ’¡ Problem Statement

Millions of people around the world suffer from conditions that make verbal communication difficult or impossible (e.g., laryngectomy, neurological disorders, or congenital conditions).  
Traditional assistive devices are often expensive or inaccessible.  

**Aroghyabhashini** aims to change this by providing an **affordable, AI-driven, multilingual communication assistant** â€” one that works on both web and hardware interfaces.

---

## ğŸ” Key Features  

âœ… **Text-to-Speech Conversion** â€“ Converts typed or selected text into clear, natural speech.  
âœ… **Multilingual Support** â€“ Supports Indian regional languages for inclusivity.  
âœ… **Translation API Integration** â€“ Automatically translates between languages before speech output.  
âœ… **Clean & Accessible UI** â€“ Simple interface designed for users with limited mobility.  
âœ… **Cloud-Backed Architecture** â€“ Ensures data safety and scalability.  
âœ… **Real-Time Voice Generation** â€“ Fast, accurate, and expressive voice synthesis.  

---

## ğŸ§± Tech Stack  

| Layer | Technologies Used |
|-------|-------------------|
| **Frontend** | React, TypeScript, Vite |
| **UI / Styling** | Tailwind CSS, shadcn-ui |
| **APIs / Services** | Bhashini API |
| **Version Control** | Git & GitHub |

---

## ğŸ“‚ Repository Structure  

```
The_Linkers-Megathon-25/
â”œâ”€â”€ public/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ assets/
â”‚   â””â”€â”€ main.tsx
â”œâ”€â”€ supabase/
â”œâ”€â”€ package.json
â”œâ”€â”€ vite.config.ts
â”œâ”€â”€ tailwind.config.ts
â”œâ”€â”€ postcss.config.js
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ .env
â”œâ”€â”€ Abstract.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation & Setup  

Follow these steps to run the project locally ğŸ‘‡  

1. **Clone the Repository**
   ```bash
   git clone https://github.com/SairamMekala22/The_Linkers-Megathon-25.git
   cd The_Linkers-Megathon-25
   ```

2. **Install Dependencies**
   ```bash
   npm install
   ```

3. **Set Environment Variables**
   - Copy `.env.example` to `.env`
   - Add your API keys and Supabase URL/credentials.

4. **Run in Development Mode**
   ```bash
   npm run dev
   ```

5. **Build for Production**
   ```bash
   npm run build
   ```

6. **Preview the Build**
   ```bash
   npm run preview
   ```

---

## ğŸ§© System Architecture  

```mermaid
flowchart TD
A[User Input] --> B[Translation Module]
B --> C[Speech Synthesis Engine]
C --> D[Audio Output]
B --> E[Multilingual Text Display]
A --> F[UI/UX Interface]
F --> B
```

---

## ğŸ§  Workflow  

1. User enters or selects input text.  
2. The system sends text to a translation API (if needed).  
3. The translated text is passed to a speech synthesis engine.  
4. The engine converts it into audible output in real time.  
5. The user hears the generated voice output through speakers.  

---

## ğŸ¨ UI Highlights  

- Minimalistic design for accessibility  
- Large buttons and simple navigation  
- Dark/light mode options  
- Responsive design for web and mobile  

---

## ğŸ‘©â€ğŸ’» Team Members  

| Name |
|------|
| **Sairam Mekala** |
| **Mallu Ram Charan Reddy** | 
| **Racharla Rakesh** | 
| **Akhilesh Rao** | 
| **Narina Ram Charan Teja** | 

---

---

## ğŸ§ª Testing & Validation  

- âœ… Integration tests for API workflows  
- âœ… Accessibility and performance checks  
- âœ… Usability testing with real users  

---

## ğŸ—ï¸ Challenges Faced  

- Handling multilingual model latency  
- Maintaining accuracy across diverse accents  
- Balancing UI simplicity with feature richness  

---

## ğŸ’¬ Outcomes  

- Functional prototype developed and deployed  
- Demonstrated real-time voice conversion  

---

## ğŸ“œ License  

```
MIT License  
Â© 2025 The Linkers â€” Aroghyabhashini Project Team, KMIT
```

---


---

## ğŸ“ Contact  

**GitHub:** [SairamMekala22](https://github.com/SairamMekala22)  
**Email:** sairam.mekala@example.com *(replace with actual email)*  
**Project Repo:** [Aroghyabhashini](https://github.com/SairamMekala22/The_Linkers-Megathon-25)  

---

> â€œTechnology gives voice to those unheard â€” Aroghyabhashini brings that voice to life.â€
